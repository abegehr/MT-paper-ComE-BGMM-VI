\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts

\usepackage{cite}
\usepackage[numbers]{natbib}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{xcolor}
\usepackage{graphicx}
\usepackage[warn]{textcomp}
\usepackage{multirow}
\usepackage{mathtools}
\usepackage{commath}
\usepackage{caption}
\usepackage{subcaption}
\usepackage[super]{nth}
\usepackage{url}

\def\UrlBreaks{\do\/\do-}

% tikz
\usepackage{tikz}
\usetikzlibrary{shapes.geometric, arrows}
% tikz styles
\tikzstyle{user} = [circle, thick, draw, minimum size=2.5cm]
\tikzstyle{item} = [rectangle, thick, draw, minimum width=3cm, minimum height=1.5cm]
\tikzstyle{arrow} = [->, draw, thick]
\tikzstyle{bi-arrow} = [<->, draw, thick]
\tikzstyle{line} = [-, draw, thick]

\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}

\emergencystretch=8em

\begin{document}

\title{Community Embeddings with Bayesian Gaussian Mixture Model and Variational Inference\\
    \thanks{The reported study was partially supported by RFBR grant \textnumero 20-07-00958. The paper was prepared within the framework of the HSE University Project Group Competition 2020-2022.}
}

\author{
    \IEEEauthorblockN{Anton I. N. Begehr}
    \IEEEauthorblockA{
        \textit{Graduate School of Business}\\
        \textit{National Research University Higher School of Economics}\\
        Moscow, Russia\\
        a.begehr@fu-berlin.de\\
    }
    \and
    \IEEEauthorblockN{Prof. Dr. Petr Panfilov}
    \IEEEauthorblockA{
        \textit{Graduate School of Business}\\
        \textit{National Research University Higher School of Economics}\\
        Moscow, Russia\\
        ppanfilov@hse.ru\\
    }
}

\maketitle

\begin{abstract}
    Graphs, such as social networks, emerge naturally from various real-world situations. Recently, graph embedding methods have gained traction in data science research.
    The graph and community embedding algorithm ComE aims to preserve first-, second- and higher-order proximity. ComE requires prior knowledge of the number of communities K. In this paper, ComE is extended to utilize a Bayesian Gaussian mixture model with variational inference for learning community embeddings (ComE BGMM+VI), similar to ComE+. ComE BGMM+VI takes K as the maximum number of communities and drops components through the trade-off hyperparameter weight concentration prior.
    The advantage of ComE BGMM+VI over the non-Bayesian ComE for an unknown number of communities K is shown for the small Karate club dataset and explored for the larger DBLP dataset.
\end{abstract}

\begin{IEEEkeywords}
    graph, embedding, community embedding, ComE, Bayesian, variational inference, Gaussian mixture, expectation maximization
\end{IEEEkeywords}


\section{Introduction}

Graphs, such as social networks, knowledge graphs, content-rating graphs, and communication networks, emerge naturally from various real-world situations. Analyzing these graphs leads to findings and understanding of the underlying structures, coherences, and dependencies. Recently, methods for embedding graph's nodes into lower-dimensional Euclidean spaces, called graph embeddings, have gained traction in multiple areas of data science research \cite{Goyal_2018}.

Community Embeddings, in addition to embedding a graph's nodes through first- and second-order proximity, also preserve higher-order proximity by embedding clusters present in the graph data. The graph and community embedding algorithm ComE aims to preserve first-, second- and higher-order proximity by embedding a graph's nodes and communities\cite{ComE}. ComE requires prior knowledge of the number of communities $K$. In this paper, ComE is extended to utilizing a Bayesian Gaussian mixture model with variational inference for learning community embeddings (ComE BGMM+VI), similar to ComE+ published by \citeauthor{ComE+} in \citeyear{ComE+} \cite{ComE+}. ComE BGMM+VI takes $K$ as the maximum number of communities and drops components through a trade-off hyperparameter.

The recent \citeyear{ComE} graph embeddings algorithm ComE is extended similarily to the \citeyear{ComE+} ComE+ by taking a Bayesian approach. The open-source code for the Bayesian approach to ComE's community embedding is published on GitHub\footnote{at \url{https://github.com/abegehr/ComE_BGMM}} and serves as a contribution to community embedding research \cite{ComE_BGMM_GH}.

The original ComE paper \textit{Learning Community Embedding with Community Detection and Node Embedding on Graphs} by \citeauthor{ComE} and the ComE+ paper \textit{Embedding Both Finite and Infinite Communities on Graphs} by \citeauthor{ComE+} in combination with the ComE source code have provided the basis and architecture for the community embeddings utilized in this work \cite{ComE, ComE+, ComE_GH}.

Multiple surveys and articles on graph embeddings were consulted to build a full picture of the current state of graph embedding research. Especially the \citeyear{Goyal_2018} survey \textit{Graph Embedding Techniques, Applications, and Performance: A Survey} by \citeauthor{Goyal_2018} and the \citeyear{rossi20tkdd-roles} paper \textit{On Proximity and Structural Role-based Embeddings in Networks: Misconceptions, Techniques, and Applications} by \citeauthor{rossi20tkdd-roles} have proven to be primary resources for understanding the current landscape of graph embedding research \cite{Goyal_2018, rossi20tkdd-roles}.

On part of comparing the Bayesian Gaussian mixture model with variational inference to the Gaussian mixture model with expectation-maximization, the \citeyear{Bishop06} book \textit{Pattern Recognition and Machine Learning (Information Science and Statistics)} by \citeauthor{Bishop06} includes essential statistics and information science knowledge and explanations \cite{Bishop06}.

\section{Community Embedding}




%%% Bibliography
\bibliographystyle{IEEEtranN}
\bibliography{literature}

\end{document}
